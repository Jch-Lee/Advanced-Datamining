---
title: "Lecture 03"
author: "Lee JongCheol"
date: "`r Sys.Date()`"
outp html_document
---

```{r}
library(ISLR)
data(Default)
summary(Default)
```

```{r}
attach(Default)
balance
```

```{r}
plot(income ~ balance, xlab="Balance", ylab="Income",
pch=c(1,3)[unclass(default)],
col=c("lightblue","red")[unclass(default)])
```

```{r}
set.seed(1234)
ss <- sample(which(default=="No"), sum(default=="Yes"))
ss <- c(ss, which(default=="Yes"))
us <- unclass(default[ss])
plot(income[ss] ~ balance[ss], xlab="Balance", pch=c(1,3)[us],
col=c("lightblue","red")[us], ylab="Income")
```

```{r}
par(mfrow=c(1,2))
boxplot(balance~default, col=c("lightblue","red"), boxwex=0.5,
xlab="Default", ylab="Balance")
boxplot(income~default, col=c("lightblue","red"), boxwex=0.5,
xlab="Default", ylab="Income")
```

```{r}
ndef <- rep(0, length(default))
ndef[default=="Yes"] <- 1
g1 <- glm(ndef ~ balance)
g2 <- glm(default ~ balance, family="binomial")
par(mfrow=c(1,2))
plot(balance, ndef, pch="|", col="orange", xlab="Balance",
ylab="Probability of Default",ylim=c(-0.1,1.1))
abline(h=c(0,1), lty=2)
lines(balance, g1$fit, col="lightblue", lwd=2)
plot(balance, as.numeric(default)-1, pch="|", col="orange",
xlab="Balance", ylab="Probability of Default",
ylim=c(-0.1,1.1))
abline(h=c(0,1), lty=2)
u <- order(balance)
lines(balance[u], g2$fit[u], col="lightblue", lwd=3)

```

### Logistic Regression with glm function

```{r}
g2 <- glm(default ~ balance, family="binomial")
summary(g2)$coef
```

```{r}
## Fitted values
g2$fit[1:10]
```

```{r}
## inverse logistic function
ilogit <- function(x, coef) {
  exp(cbind(1, x) %*% coef) / (1 + exp(cbind(1, x) %*% coef))
}
cbind(g2$fit, ilogit(balance, g2$coef))[1:100,]
```

```{r}
ilogit(1000, g2$coef)
```

```{r}
g3 <- glm(default ~ student, family="binomial")
summary(g3)$coef
```

```{r}
## Student "Yes"
ilogit(1, g3$coef)
```

```{r}
## Student "No"
ilogit(0, g3$coef)
```

```{r}
g4 <- glm(default~ balance + income + student, family="binomial") # 여러 변수 사용
round(summary(g4)$coef, 4)
```

```{r}
yst <- g4$fit[student=="Yes"]
nst <- g4$fit[student=="No"]
plot(balance, g2$fit, col="white", xlab="Credit Card Balance",
ylab="Default Rate")
abline(h=0)
abline(h=mean(yst), lty=2, col="orange")
abline(h=mean(nst), lty=2, col="lightblue")
u1 <- order(balance[student=="Yes"])
u2 <- order(balance[student=="No"])
lines(balance[student=="Yes"][u1], yst[u1], col="orange", lwd=2)
lines(balance[student=="No"][u2], nst[u2], col="lightblue", lwd=2)

```

```{r}
balance <- balance

boxplot(balance ~ student, col=c("lightblue","orange"),
xlab="Student Status", ylab="Credit Card Balance", boxwex=0.6)

```

```{r}
ilogit(cbind(1500, 40, 1), g4$coef)
```

```{r}
ilogit(cbind(1500, 40, 0), g4$coef)
```

```{r}
xb <- predict(g4, data.frame(balance=1500, income=40, student="Yes"))
exp(xb)/(1+exp(xb))
```

```{r}
predict(g4, data.frame(balance=1500, income=40, student="Yes"),type="response")
```

```{r}
set.seed(1111)
n <- nrow(Default)
train <- sample(1:n, n*0.7)
test <- setdiff(1:n, train)
g1 <- glm(default ~ balance, family="binomial", subset=train)
g2 <- glm(default ~ student, family="binomial", subset=train)
g3 <- glm(default ~ income, family="binomial", subset=train)
g4 <- glm(default~ balance+student+income, family="binomial",
subset=train)
miss <- NULL
for (k in 1:4) {
  g <- get(paste("g", k, sep=""))
  pred <- predict(g, Default, type="response")[test]
  yhat <- rep(0, length(test))
  yhat[pred > 0.5] <- 1
  miss[k] <- mean(yhat!=as.numeric(default[test])-1)
}
miss

```

```{r}
install.packages("nnet")
```

```{r}
library(HDclassif)
library(nnet)
data(wine)
colnames(wine) <- c('Type', 'Alcohol', 'Malic', 'Ash', 
                      'Alcalinity', 'Magnesium', 'Phenols', 
                      'Flavanoids', 'Nonflavanoids',
                      'Proanthocyanins', 'Color', 'Hue', 
                      'Dilution', 'Proline')
wine$Type <- as.factor(wine$Type)
str(wine)
```

```{r}
summary(wine)
```

```{r}
plot(wine[, -1], col=as.numeric(wine$Type) + 1)
```

```{r}
plot(wine[, 2:7], col=as.numeric(wine$Type) + 1)
```

```{r}
plot(wine[, 8:14], col=as.numeric(wine$Type) + 1)
```

```{r}
fit <- multinom(Type ~ ., data=wine, trace=FALSE)
summary(fit)
```

```{r}
z <- coef(summary(fit))/summary(fit)$standard.errors
pnorm(abs(z), lower.tail=FALSE)*2
```

```{r}
set.seed(1)
u <- sort(sample(1:nrow(wine), 10))
fitted(fit)[u,]
```

```{r}
predict(fit, wine, type="prob")[u,]
```

```{r}
prob0 <- predict(fit, wine, type="prob")
pred0 <- apply(prob0, 1, which.max)
table(pred0, wine$Type)

```

```{r}
pred0a <- predict(fit, wine, type="class")
table(pred0a, wine$Type)

```

```{r}
set.seed(1111)
n <- nrow(wine)
train <- sample(1:n, round(n*0.7))
test <- setdiff(1:n, train)
fit1 <- multinom(Type ~ Alcohol + Color, data=wine,
subset=train)
summary(fit1)

```

```{r}
pred1 <- predict(fit1, wine, type="class")
tab1 <- table(pred1[test], wine$Type[test])
1-sum(diag(tab1))/sum(tab1) # 비대각원소=오분류
```

```{r}
fit2 <- multinom(Type ~ ., data=wine, subset=train)
summary(fit2)
```

```{r}
pred2 <- predict(fit2, wine, type="class")
tab2 <- table(pred2[test], wine$Type[test])
1-sum(diag(tab2))/sum(tab2)
```

```{r}
set.seed(12345)
miss <- NULL
for (k in 1:100) {
  train <- sample(1:n, round(n*0.7))
  test <- setdiff(1:n, train)
  g <- multinom(Type ~ ., data=wine, subset=train, trace=FALSE)
  pred <- predict(g, wine, type="class")
  tab <- table(pred[test], wine$Type[test])
  miss[k] <- 1-sum(diag(tab))/sum(tab)
}
summary(miss)

```

```{r}
hist(miss, main="Classification Error Rate", col="orange")
```

### LDA

```{r}
x <- seq(-5, 5, 0.1)
plot(x, dnorm(x, -1.5, 1), type="l", col="darkgreen", xlab="",
ylab="", yaxt="n", xlim=c(-5,5), lwd=2)
lines(x, dnorm(x, 1.5, 1), col="red", lwd=2)
abline(v=0, lwd=3, lty=2)
```

```{r}
x1 <- rnorm(20, -1.5, 1)
x2 <- rnorm(20, 1.5, 1)
hist(x1, col=rgb(0.4,1,0,0.8), breaks=10, xlab="", ylab="",
main="", xlim=c(-4,4))
hist(x2, col=rgb(0.7,0,0,0.7), breaks=10, add=T)
abline(v=0, lwd=3, lty=2)
abline(v=(mean(x1)+mean(x2))/2, lwd=3, lty=1)
legend("topleft", c("True", "Estimated"), lty=c(2,1), lwd=1,
bty="n", cex=0.9)

```

```{r}
## Open the iris dataset
data(iris)
str(iris)
```

```{r}
summary(iris)
```

```{r}
plot(iris[, -5], col=as.numeric(iris$Species) + 1)
```

```{r}
## Apply LDA for iris data
library(MASS)
g <- lda(Species ~., data=iris)
plot(g)
```

```{r}
plot(g, dimen=1)
```

```{r}
## Compute misclassification error for training sets
pred <- predict(g)
table(pred$class, iris$Species)
```

```{r}
mean(pred$class!=iris$Species)
```

```{r}
## Randomly separate training sets and test sets
set.seed(1234)
tran <- sample(nrow(iris), size=floor(nrow(iris)*2/3))
g <- lda(Species ~., data=iris, subset=tran)

## Compute misclassification error for test sets
pred <- predict(g, iris)$class[-tran]
test <- iris$Species[-tran]
table(pred, test)
```

```{r}
mean(pred!=test)
```

```{r}
## Posterior probability
post <- predict(g, iris)$posterior[-tran,] # test sample들의 각 클래스 확률 계산
post[1:10,]
```

```{r}
apply(post, 1, which.max)
```

```{r}
as.numeric(pred)
```

### LDA vs Multinom

```{r}
library(nnet)
set.seed(1234)
K <- 100
RES <- array(0, c(K, 2))
for (i in 1:K) {
  tran.num <- sample(nrow(iris), size=floor(nrow(iris)*2/3))
  tran <- as.logical(rep(0, nrow(iris)))
  tran[tran.num] <- TRUE
  g1 <- lda(Species ~., data=iris, subset=tran)
  g2 <- multinom(Species ~., data=iris, subset=tran, trace=FALSE)
  pred1 <- predict(g1, iris[!tran,])$class
  pred2 <- predict(g2, iris[!tran,])
  RES[i, 1] <- mean(pred1!=iris$Species[!tran])
  RES[i, 2] <- mean(pred2!=iris$Species[!tran])
}

apply(RES, 2, mean)
```

```{r}
data(wine)
colnames(wine) <- c('Type', 'Alcohol', 'Malic', 'Ash', 
                      'Alcalinity', 'Magnesium', 'Phenols', 
                      'Flavanoids', 'Nonflavanoids',
                      'Proanthocyanins', 'Color', 'Hue', 
                      'Dilution', 'Proline')
wine$Type <- as.factor(wine$Type)


set.seed(1111)
RES2 <- array(0, c(K, 2))
for (i in 1:K) {
  tran.num <- sample(nrow(wine), size=floor(nrow(wine)*2/3))
  tran <- as.logical(rep(0, nrow(wine)))
  tran[tran.num] <- TRUE
  g1 <- lda(Type ~., data=wine, subset=tran)
  g2 <- multinom(Type ~., data=wine, subset=tran, trace=FALSE)
  pred1 <- predict(g1, wine[!tran,])$class
  pred2 <- predict(g2, wine[!tran,])
  RES2[i, 1] <- mean(pred1!=wine$Type[!tran])
  RES2[i, 2] <- mean(pred2!=wine$Type[!tran])
}
apply(RES2, 2, mean)

```

### LDA on Default Data

```{r}
library(ISLR)
data(Default)
attach(Default)
library(MASS)
g <- lda(default~., data=Default)
pred <- predict(g, default)
table(pred$class, default)
```

```{r}
mean(pred$class!=default)
```

### Changes in Errors along with Different Thresholds

```{r}
thre <- seq(0,1,0.01)
res <- matrix(NA, length(thre), 3)

## Compute overall error, false positives, false negatives
for (i in 1:length(thre)) {
  decision <- rep("No", length(default))
  decision[pred$posterior[,2] >= thre[i]] <- "Yes"
  res[i, 1] <- mean(decision != default)
  res[i, 2] <- mean(decision[default=="No"]=="Yes")
  res[i, 3] <- mean(decision[default=="Yes"]=="No")
}
k <- 1:51

matplot(thre[k], res[k,], col=c(1,"orange",4), lty=c(1,4,2),
type="l", xlab="Threshold", ylab="Error Rate", lwd=2)
legend("top", c("Overall Error", "False Positive",
"False Negative"), col=c(1,"orange",4), lty=c(1,4,2),
cex=1.2)

```

```{r}
apply(res, 2, which.min)
```

### ROC curve

```{r}
thre <- seq(0,1,0.001)
Sen <- Spe <- NULL
RES <- matrix(NA, length(thre), 4)
colnames(RES) <- c("TP", "TN", "FP", "FN")

for (i in 1:length(thre)) {
  decision <- rep("No", length(default))
  decision[pred$posterior[,2] >= thre[i]] <- "Yes"
  Sen[i] <- mean(decision[default=="Yes"] == "Yes")
  Spe[i] <- mean(decision[default=="No"] == "No")
  RES[i,1] <- sum(decision[default=="Yes"] == "Yes")
  RES[i,2] <- sum(decision[default=="No"] == "No")
  RES[i,3] <- sum(decision=="Yes") - RES[i,1]
  RES[i,4] <- sum(default=="Yes") - RES[i,1]
}

plot(1-Spe, Sen, type="b", pch=20, xlab="False positive rate",
col="darkblue", ylab="True positive rate", main="ROC Curve")
abline(0, 1, lty=3, col="gray")

```

```{r}
TPR <- RES[,1] / (RES[,1] + RES[,4])
TNR <- RES[,2] / (RES[,2] + RES[,3])
plot(1-TNR, TPR, type="b", pch=20, xlab="False positive rate",
col="darkblue", ylab="True positive rate", main="ROC Curve")
abline(0, 1, lty=3, col="gray")
```

```{r}
PPV <- RES[,1] / (RES[,1] + RES[,3])
NPV <- RES[,2] / (RES[,2] + RES[,4])
MAT <- cbind(TPR, TNR, PPV, NPV)
matplot(thre, MAT, type="l", lty=c(1,2,1,2), col=c(1,1,2,2),
xlab="thresholds", ylab="")
legend("right", c("TPR", "TNR", "PPV", "NPV"),
lty=c(1,2,1,2), col=c(1,1,2,2), bty="n", cex=1.2)
```

```{r}
library(ROCR)
## Compute ROC curve
label <- factor(default, levels=c("Yes","No"),
labels=c("TRUE","FALSE"))
preds <- prediction(pred$posterior[,2], label)
perf <- performance(preds, "tpr", "fpr" )
plot(perf, lwd=4, col="darkblue")
abline(a=0, b=1, lty=2)
```

```{r}
slotNames(perf)
```

```{r}
k <- 1:100
list(perf@x.name, perf@x.values[[1]][k])
list(perf@y.name, perf@y.values[[1]][k])
list(perf@alpha.name, perf@alpha.values[[1]][k])
```

```{r}
## Compute AUC
performance(preds, "auc")@y.values
```

### LDA vs. QDA: Default Data

```{r}
library(MASS)
set.seed(1234)
n <- nrow(Default)
train <- sample(1:n, n*0.7)
test <- setdiff(1:n, train)
```

```{r}
## Classification error rate of LDA
g1 <- lda(default~., data=Default, subset=train)
pred1 <- predict(g1, Default)
table(pred1$class[test], Default$default[test])
```

```{r}
mean(pred1$class[test]!=Default$default[test])
```

```{r}
## Classification error rate of QDA
g2 <- qda(default~., data=Default, subset=train)
pred2 <- predict(g2, Default)
table(pred2$class[test], Default$default[test])
```

```{r}
mean(pred2$class[test]!=Default$default[test])
```

```{r}
## AUC comparison between LDA and QDA
library(ROCR)
label <- factor(default[test], levels=c("Yes","No"),
labels=c("TRUE","FALSE"))
preds1 <- prediction(pred1$posterior[test,2], label)
preds2 <- prediction(pred2$posterior[test,2], label)

performance(preds1, "auc")@y.values
```

```{r}
performance(preds2, "auc")@y.values
```

```{r}
set.seed(123)
N <- 100
CER <- AUC <- matrix(NA, N, 2)

for (i in 1:N) {
  train <- sample(1:n, n*0.7)
  test <- setdiff(1:n, train)
  y.test <- Default$default[test]
  g1 <- lda(default~., data=Default, subset=train)
  g2 <- qda(default~., data=Default, subset=train)
  pred1 <- predict(g1, Default)
  pred2 <- predict(g2, Default)
  CER[i,1] <- mean(pred1$class[test]!=y.test)
  CER[i,2] <- mean(pred2$class[test]!=y.test)
  label <- factor(default[test], levels=c("Yes","No"),
  labels=c("TRUE","FALSE"))
  preds1 <- prediction(pred1$posterior[test,2], label)
  preds2 <- prediction(pred2$posterior[test,2], label)
  AUC[i,1] <- as.numeric(performance(preds1, "auc")@y.values)
  AUC[i,2] <- as.numeric(performance(preds2, "auc")@y.values)
}

apply(CER, 2, mean)
```

```{r}
apply(AUC, 2, mean)
```

### Naive Bayes

```{r}
data(iris)
library(e1071)
g1 <- naiveBayes(Species ~ ., data = iris)
g1 <- naiveBayes(iris[,-5], iris[,5])
pred <- predict(g1, iris[,-5])
table(pred, iris[,5])
```

```{r}
mean(pred!=iris$Species)
```

```{r}
## Randomly separate training sets and test sets
set.seed(1234)
tran <- sample(nrow(iris), size=floor(nrow(iris)*2/3))
## Compute misclassification error for test sets
g2 <- naiveBayes(Species ~ ., data=iris, subset=tran)
pred2 <- predict(g2, iris)[-tran]
test <- iris$Species[-tran]
table(pred2, test)
```

```{r}
mean(pred2!=test)
```

```{r}
data(Default)
set.seed(1234)
n <- nrow(Default)
train <- sample(1:n, n*0.7)
test <- setdiff(1:n, train)
g3 <- naiveBayes(default ~ ., data=Default, subset=train)
pred3 <- predict(g3, Default)[test]
table(pred3, Default$default[test])
```

```{r}
mean(pred3!=Default$default[test])
```

```{r}
## AUC of Naive Bayes
library(ROCR)
label <- factor(default[test], levels=c("Yes","No"),
labels=c("TRUE","FALSE"))
pred4 <- predict(g3, Default, type="raw")
preds <- prediction(pred4[test, 2], label)
performance(preds, "auc")@y.values
```

### KNN method

```{r}
library(class)
data(iris)
set.seed(1234)
tran <- sample(nrow(iris), size=floor(nrow(iris)*2/3))
tran.x <- iris[tran, -5]
test.x <- iris[-tran, -5]
tran.y <- iris$Species[tran]
test.y <- iris$Species[-tran]


knn.pred <- knn(tran.x, test.x, tran.y, k=3)
table(knn.pred, test.y)
```

```{r}
mean(test.y!=knn.pred)
```

```{r}
knn.pred <- knn(tran.x, test.x, tran.y, k=13)
table(knn.pred, test.y)
```

```{r}
mean(test.y!=knn.pred)
```

```{r}
set.seed(1)
K <- 50
k <- 1:50
mis <- matrix(0, K, length(k))
for (i in 1:K) {
  tran <- sample(nrow(iris), size=floor(nrow(iris)*2/3))
  tran.x <- iris[tran, -5]
  test.x <- iris[-tran, -5]
  tran.y <- iris$Species[tran]
  test.y <- iris$Species[-tran]
  for (j in 1:length(k)) {
    knn.pred <- knn(tran.x, test.x, tran.y, k=k[j])
    mis[i, j] <- mean(test.y!=knn.pred)
  }
}
err <- apply(mis, 2, mean)
plot(k, err, type="b", xlab="k", ylab="Mis-classification Error",
col=2, pch=20)

```

```{r}
which.min(err)
```
